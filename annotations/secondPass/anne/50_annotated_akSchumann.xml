<?xml version="1.0" encoding="UTF-8"?>
<corpus>

<paper id="P06-2067"><title><entity>Parsing And Subcategorization Data</entity></title><abstract>
In this paper, we compare the performance of a state-of-the-art <entity>statistical parser</entity> ( <BIBLIO>Bikel, 2004</BIBLIO> ) in parsing <entity>written and spoken language</entity> and in generating <entity>sub-categorization cues</entity> from <entity>written and spoken language</entity>. Although <entity><PERSON>Bikel</PERSON> 's parser</entity> achieves a higher <entity>accuracy</entity> for parsing <entity>written language</entity>, it achieves a higher <entity>accuracy</entity> when extracting <entity>subcategorization cues</entity> from <entity>spoken language</entity>. Our experiments also show that current technology for extracting <entity>subcategorization frames</entity> initially designed for <entity>written texts</entity> works equally well for <entity>spoken language</entity>. Additionally, we explore the utility of <entity>punctuation</entity> in helping <entity>parsing</entity> and <entity>extraction</entity> of <entity>subcategorization cues</entity>. Our experiments show that <entity>punctuation</entity> is of little help in parsing <entity>spoken language</entity> and extracting <entity>subcategorization cues</entity> from <entity>spoken language</entity>. This indicates that there is no need to add <entity>punctuation</entity> in transcribing <entity>spoken corpora</entity> simply in order to help <entity>parsers</entity>.
</abstract></paper>

<paper id="C94-1088" for="C94-1089"><title>
<entity>Character-Based Collocation</entity> For <entity>Mandarin Chinese</entity></title><abstract>
This paper describes a <entity>characters-based Chinese collocation system</entity> and discusses the advantages of it over a traditional <entity>word-based system</entity>. Since <entity>wordbreaks</entity> are not conventionally marked in <entity>Chinese text corpora</entity>, a <entity>character-based collocation system</entity> has the dual advantages of avoiding <entity>pre-processing distortion</entity> and directly accessing <entity>sub-lexical information</entity>. Furthermore, <entity>word-based collocational properties</entity> can be obtained through an auxiliary module of <entity>automatic segmentation</entity>.
</abstract></paper>

<paper id="C04-1024"><title>
Efficient <entity>Parsing</entity> Of <entity>Highly Ambiguous Context-Free Grammars</entity> With <entity>Bit Vectors</entity>
</title><abstract>
An efficient <entity>bit-vector-based CKY-style parser</entity> for <entity>context-free parsing</entity> is presented. The <entity>parser</entity> computes a compact <entity>parse forest representation</entity> of the complete set of possible analyses for <entity>large treebank grammars</entity> and long <entity>input sentences</entity>. The <entity>parser</entity> uses <entity>bit-vector operations</entity> to parallelise the <entity>basic parsing operations</entity>. The <entity>parser</entity> is particularly useful when all analyses are needed rather than just the most probable one.
</abstract></paper>

<paper id="N04-1008"><title><entity>Automatic Question Answering</entity>: Beyond The Factoid</title><abstract>
In this paper we describe and evaluate a <entity>Question Answering system</entity> that goes beyond answering <entity>factoid questions</entity>. We focus on <entity>FAQ-like questions</entity> and <entity>answers</entity>, and build our system around a <entity>noisy-channel architecture</entity> which exploits both a <entity>language model</entity> for <entity>answers</entity> and a <entity>transformation model</entity> for <entity>answer/question terms</entity>, trained on a <entity>corpus</entity> of 1 million <entity>question/answer pairs</entity> collected from the Web.
</abstract></paper>

<paper id="E93-1066" for="E93-1065"><title>
<entity>Two-Level Description</entity> Of <entity>Turkish Morphology</entity></title><abstract>
This poster paper describes a <entity>full scale two-level morphological description</entity> ( <BIBLIO>Karttunen, 1983</BIBLIO> , Kosken-niemi, 1983) of <entity>Turkish word structures</entity>. The description has been implemented using the <entity>PC-KIMMO environment</entity> ( <BIBLIO>Antworth, 1990</BIBLIO> ) and is based on a <entity>root word lexicon</entity> of about 23,000 <entity>roots words</entity>. Almost all the <entity>special cases</entity> of and <entity>exceptions</entity> to <entity>phonological and morphological rules</entity> have been implemented. <entity>Turkish</entity> is an <entity>agglutinative language</entity> with <entity>word structures</entity> formed by <entity>productive affixations</entity> of <entity>derivational and inflectional suffixes</entity> to <entity>root words</entity>. <entity>Turkish</entity> has <entity>finite-state</entity> but nevertheless rather complex <entity>morphotactics</entity>. <entity>Morphemes</entity> added to a <entity>root word</entity> or a <entity>stem</entity> can convert the <entity>word</entity> from a <entity>nominal</entity> to a <entity>verbal structure</entity> or vice-versa, or can create <entity>adverbial constructs</entity>. The <entity>surface realizations</entity> of <entity>morphological constructions</entity> are constrained and modified by a number of <entity>phonetic rules</entity> such as <entity>vowel harmony</entity>.
</abstract></paper>

<paper id="X96-1041" for="X96-1043"><title>
<entity>TUIT</entity>: A <entity>Toolkit For Constructing Multilingual TIPSTER User Interfaces</entity>
</title><abstract>
The <entity>TIPSTER Architecture</entity> has been designed to enable a variety of different <entity>text applications</entity> to use a set of common <entity>text processing modules</entity>. Since <entity>user interfaces</entity> work best when customized for particular <entity>applications</entity>, it is appropriator that no particular <entity>user interface styles or conventions</entity> are described in the <entity>TIPSTER Architecture specification</entity>. However, the <entity>Computing Research Laboratory (CRL)</entity> has constructed several <entity>TIPSTER applications</entity> that use a common set of configurable <entity>Graphical User Interface (GUI) functions</entity>. These <entity>GUIs</entity> were constructed using <entity>CRL's TIPSTER User Interface Toolkit (TUIT)</entity>. 
</abstract></paper>

<paper id="P98-2176"><title>Learning <entity>Correlations</entity> between <entity>Linguistic Indicators</entity> and <entity>Semantic Constraints</entity>: Reuse of <entity>Context-Dependent Descriptions</entity> of <entity>Entities</entity>
</title><abstract>
This paper presents the results of a study on the <entity>semantic constraints</entity> imposed on <entity>lexical choice</entity> by certain <entity>contextual indicators</entity>. We show how such <entity>indicators</entity> are computed and how <entity>correlations</entity> between them and the <entity>choice</entity> of a <entity>noun phrase description</entity> of a <entity>named entity</entity> can be automatically established using <entity>supervised learning</entity>. Based on this <entity>correlation</entity>, we have developed a technique for <entity>automatic lexical choice</entity> of <entity>descriptions</entity> of <entity>entities</entity> in <entity>text generation</entity>. We discuss the underlying relationship between the <entity>pragmatics</entity> of choosing an appropriate <entity>description</entity> that serves a specific purpose in the <entity>automatically generated text</entity> and the <entity>semantics</entity> of the <entity>description</entity> itself. We present our work in the framework of the more general concept of reuse of <entity>linguistic structures</entity> that are automatically extracted from <entity>large corpora</entity>. We present a formal evaluation of our approach and we conclude with some thoughts on potential applications of our method.
</abstract></paper>

<paper id="H94-1024"><title><entity>Evaluation</entity> In The <entity>ARPA Machine Translation Program</entity>: 1993 Methodology</title><abstract>
In the second year of <entity>evaluations</entity> of the <entity>ARPA HLT Machine Translation (MT) Initiative</entity>, methodologies developed and tested in 1992 were applied to the <entity>1993 MT test runs</entity>. The current methodology optimizes the inherently subjective <entity>judgments on translation accuracy and quality</entity> by channeling the <entity>judgments</entity> of <entity>non-translators</entity> into many<entity>data points</entity> which reflect both the comparison of the <entity>performance</entity> of the <entity>research MT systems</entity> with <entity>production MT systems</entity> and against the <entity>performance</entity> of <entity>novice translators</entity>. This paper discusses the three <entity>evaluation methods</entity> used in the <entity>1993 evaluation</entity>, the results of the <entity>evaluations</entity>, and preliminary characterizations of the <entity><BIBLIO>Winter 1994</BIBLIO>  evaluation</entity>, now underway. The efforts under discussion focus on measuring the progress of core <entity>MT technology</entity> and increasing the sensitivity and <entity>portability</entity> of <entity>MT evaluation methodology</entity>.1. <entity>INTRODUCTION</entity>.
</abstract></paper>

</corpus>