<?xml version="1.0" encoding="UTF-8"?>
<corpus>

<paper id="P06-2067"><title><entity>Parsing</entity> And Subcategorization <entity>Data</entity></title><abstract>
In this <entity>paper</entity>, we compare the <entity>performance</entity> of a state-of-the-art <entity>statistical</entity> <entity>parser</entity> ( <BIBLIO>Bikel, 2004</BIBLIO> ) in <entity>parsing</entity> written and spoken <entity>language</entity> and in <entity>generating</entity> <entity>sub-categorization</entity> <entity>cues</entity> from written and spoken <entity>language</entity>. Although <PERSON>Bikel</PERSON> 's <entity>parser</entity> achieves a higher <entity>accuracy</entity> for <entity>parsing</entity> written <entity>language</entity>, it achieves a higher <entity>accuracy</entity> when <entity>extracting</entity> subcategorization <entity>cues</entity> from spoken <entity>language</entity>. Our <entity>experiments</entity> also show that <entity>current</entity> <entity>technology</entity> for <entity>extracting</entity> subcategorization <entity>frames</entity> initially <entity>designed</entity> for written <entity>texts</entity> works equally well for spoken <entity>language</entity>. Additionally, we explore the <entity>utility</entity> of <entity>punctuation</entity> in <entity>helping</entity> <entity>parsing</entity> and <entity>extraction</entity> of subcategorization <entity>cues</entity>. Our <entity>experiments</entity> show that <entity>punctuation</entity> is of little <entity>help</entity> in <entity>parsing</entity> spoken <entity>language</entity> and <entity>extracting</entity> subcategorization <entity>cues</entity> from spoken <entity>language</entity>. This indicates that there is no need to add <entity>punctuation</entity> in transcribing spoken <entity>corpora</entity> simply in <entity>order</entity> to <entity>help</entity> <entity>parsers</entity>.
</abstract></paper>

<paper id="C94-1088" for="C94-1089"><title>
Character-<entity>Based</entity> <entity>Collocation</entity> For Mandarin <entity>Chinese</entity></title><abstract>
This <entity>paper</entity> describes a characters-based <entity>Chinese</entity> <entity>collocation</entity> <entity>system</entity> and discusses the <entity>advantages</entity> of it over a traditional <entity>word-based system</entity>. Since wordbreaks <entity>arc</entity> not conventionally marked in <entity>Chinese</entity> <entity>text</entity> <entity>corpora</entity>, a character-based <entity>collocation</entity> <entity>system</entity> has the dual <entity>advantages</entity> of avoiding <entity>pre-processing</entity> <entity>distortion</entity> and directly <entity>accessing</entity> <entity>sub-lexical information</entity>. Furthermore, <entity>word-based</entity> collocational <entity>properties</entity> can be obtained through an auxiliary <entity>module</entity> of <entity>automatic</entity> segmentation.
</abstract></paper>

<paper id="C04-1024"><title>
Efficient <entity>Parsing</entity> Of Highly Ambiguous <entity>Context-</entity>Free Grammars With Bit Vectors
</title><abstract>
An efficient <entity>bit-vector-based</entity> CKY-style <entity>parser</entity> for <entity>context-free</entity> <entity>parsing</entity> is presented. The <entity>parser</entity> <entity>computes</entity> a compact <entity>parse</entity> <entity>forest</entity> <entity>representation</entity> of the complete set of possible <entity>analyses</entity> for large treebank grammars and long <entity>input</entity> <entity>sentences</entity>. The <entity>parser</entity> uses <entity>bit-vector</entity> <entity>operations</entity> to parallelise the <entity>basic</entity> <entity>parsing</entity> <entity>operations</entity>. The <entity>parser</entity> is particularly useful when all <entity>analyses</entity> are needed rather than just the most probable one.
</abstract></paper>

<paper id="N04-1008"><title><entity>Automatic</entity> <entity>Question Answering</entity>: Beyond The <entity>Factoid</entity></title><abstract>
In this <entity>paper</entity> we describe and <entity>evaluate</entity> a <entity>Question Answering system</entity> that goes beyond answering <entity>factoid</entity> <entity>questions</entity>. We <entity>focus</entity> on FAQ-like <entity>questions</entity> and answers, and build our <entity>system</entity> around a <entity>noisy-channel</entity> <entity>architecture</entity> which exploits both a <entity>language model</entity> for answers and a <entity>transformation</entity> <entity>model</entity> for answer/<entity>question</entity> <entity>terms</entity>, <entity>trained</entity> on a <entity>corpus</entity> of 1 million <entity>question</entity>/answer <entity>pairs</entity> collected from the Web.
</abstract></paper>

<paper id="E93-1066" for="E93-1065"><title>
Two-<entity>Level</entity> <entity>Description</entity> Of Turkish <entity>Morphology</entity></title><abstract>
This poster <entity>paper</entity> describes a full <entity>scale</entity> <entity>two-level</entity> morphological <entity>description</entity> ( <BIBLIO>Karttunen, 1983</BIBLIO> , Kosken-niemi, 1983) of Turkish <entity>word</entity> <entity>structures</entity>. The <entity>description</entity> has been <entity>implemented</entity> using the PC-KIMMO <entity>environment</entity> ( <BIBLIO>Antworth, 1990</BIBLIO> ) and is <entity>based</entity> on a root <entity>word</entity> <entity>lexicon</entity> of about 23,000 roots <entity>words</entity>. Almost all the <entity>special cases</entity> of and <entity>exceptions</entity> to phonological and morphological <entity>rules</entity> have been <entity>implemented</entity>. Turkish is an agglutinative <entity>language</entity> with <entity>word</entity> <entity>structures</entity> <entity>formed</entity> by productive affixations of derivational and inflectional <entity>suffixes</entity> to root <entity>words</entity>. Turkish has finite-state but nevertheless rather <entity>complex</entity> <entity>mor-photactics</entity>. Morphemes added to a root <entity>word</entity> or a <entity>stem</entity> can convert the <entity>word</entity> from a nominal to a <entity>verbal</entity> <entity>structure</entity> or <entity>vice-versa</entity>, or can create adverbial <entity>constructs</entity>. The <entity>surface</entity> <entity>realizations</entity> of morphological <entity>constructions</entity> are constrained and modified by a <entity>number</entity> of phonetic <entity>rules</entity> such as <entity>vowel</entity> harmony.
</abstract></paper>

<paper id="X96-1041" for="X96-1043"><title>
TUIT: A Toolkit For Constructing Multilingual TIPSTER <entity>User</entity> Interfaces
</title><abstract>
The TIPSTER <entity>Architecture</entity> has been <entity>designed</entity> to enable a <entity>variety</entity> of different <entity>text</entity> <entity>applications</entity> to use a set of <entity>common</entity> <entity>text processing</entity> <entity>modules</entity>. Since <entity>user interfaces</entity> work best when customized for particular <entity>applications</entity>, it is appropriator that no particular <entity>user interface</entity> styles or <entity>conventions</entity> are described in the TIPSTER <entity>Architecture</entity> <entity>specification</entity>. However, the <entity>Computing</entity> <entity>Research</entity> <entity>Laboratory</entity> (CRL) has <entity>constructed</entity> several TIPSTER <entity>applications</entity> that use a <entity>common</entity> set of configurable Graphical <entity>User Interface</entity> (GUI) <entity>functions</entity>. These GUIs were <entity>constructed</entity> using CRL's TIPSTER <entity>User Interface</entity> Toolkit (TUIT). 
</abstract></paper>

<paper id="P98-2176"><title><entity>Learning</entity> Correlations between Linguistic Indicators and <entity>Semantic</entity> Constraints: Reuse of <entity>Context-</entity>Dependent Descriptions of Entities
</title><abstract>
This <entity>paper</entity> presents the <entity>results</entity> of a <entity>study</entity> on the <entity>semantic</entity> <entity>constraints</entity> imposed on <entity>lexical choice</entity> by certain contextual <entity>indicators</entity>. We show how such <entity>indicators</entity> are computed and how <entity>correlations</entity> between them and the <entity>choice</entity> of a <entity>noun phrase</entity> <entity>description</entity> of a <entity>named</entity> <entity>entity</entity> can be automatically established using <entity>supervised learning</entity>. <entity>Based</entity> on this <entity>correlation</entity>, we have <entity>developed</entity> a <entity>technique</entity> for <entity>automatic</entity> <entity>lexical choice</entity> of <entity>descriptions</entity> of <entity>entities</entity> in <entity>text generation</entity>. We discuss the underlying <entity>relationship</entity> between the pragmatics of choosing an appropriate <entity>description</entity> that serves a specific <entity>purpose</entity> in the automatically <entity>generated</entity> <entity>text</entity> and the <entity>semantics</entity> of the <entity>description</entity> itself. We present our work in the <entity>framework</entity> of the more general <entity>concept</entity> of reuse of <entity>linguistic structures</entity> that are automatically <entity>extracted</entity> from large <entity>corpora</entity>. We present a formal <entity>evaluation</entity> of our <entity>approach</entity> and we conclude with some thoughts on potential <entity>applications</entity> of our <entity>method</entity>.
</abstract></paper>

<paper id="H94-1024"><title><entity>Evaluation</entity> In The ARPA <entity>Machine Translation</entity> <entity>Program</entity>: 1993 <entity>Methodology</entity></title><abstract>
In the second year of <entity>evaluations</entity> of the ARPA HLT <entity>Machine Translation</entity> (MT) <entity>Initiative</entity>, <entity>methodologies</entity> <entity>developed</entity> and <entity>tested</entity> in 1992 were <entity>applied</entity> to the 1993 MT <entity>test</entity> runs. The <entity>current</entity> <entity>methodology</entity> optimizes the inherently subjective <entity>judgments</entity> on <entity>translation</entity> <entity>accuracy</entity> and <entity>quality</entity> by <entity>channeling</entity> the <entity>judgments</entity> of non-translators into many<entity>data</entity> points which reflect both the <entity>comparison</entity> of the <entity>performance</entity> of the <entity>research</entity> <entity>MT systems</entity> with production <entity>MT systems</entity> and against the <entity>performance</entity> of <entity>novice</entity> <entity>translators</entity>. This <entity>paper</entity> discusses the three <entity>evaluation methods</entity> used in the 1993 <entity>evaluation</entity>, the <entity>results</entity> of the <entity>evaluations</entity>, and preliminary <entity>characterizations</entity> of the <BIBLIO>Winter 1994</BIBLIO>  <entity>evaluation</entity>, now underway. The <entity>efforts</entity> under <entity>discussion</entity> <entity>focus</entity> on measuring the.<entity>progress</entity> of <entity>core</entity> MT <entity>technology</entity> and <entity>increasing</entity> the <entity>sensitivity</entity> and <entity>portability</entity> of <entity>MT evaluation</entity> <entity>methodology</entity>.1. <entity>INTRODUCTION</entity>.
</abstract></paper>

</corpus>