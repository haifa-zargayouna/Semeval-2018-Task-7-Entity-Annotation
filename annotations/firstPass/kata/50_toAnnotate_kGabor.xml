<?xml version="1.0" encoding="UTF-8"?>
<corpus>

<paper id="P06-1112" for="P06-1111"><title>
Exploring <entity>Correlation</entity> Of <entity>Dependency Relation</entity> Paths For Answer <entity>Extraction</entity></title><abstract>
In this <entity>paper</entity>, we explore <entity>correlation</entity> of <entity>dependency relation</entity> <entity>paths</entity> to <entity>rank</entity> <entity>candidate</entity> answers in answer <entity>extraction</entity>. Using the <entity>correlation</entity> measure, we compare <entity>dependency relations</entity> of a <entity>candidate</entity> answer and <entity>mapped</entity> <entity>question</entity> <entity>phrases</entity> in <entity>sentence</entity> with the corresponding <entity>relations</entity> in <entity>question</entity>. Different from previous <entity>studies</entity>, we <entity>propose</entity> an approximate <entity>phrase</entity> <entity>mapping</entity> <entity>algorithm</entity> and incorporate the <entity>mapping</entity> score into the <entity>correlation</entity> measure. The <entity>correlations</entity> are further incorporated into a <entity>Maximum Entropy-based</entity> <entity>ranking model</entity> which estimates <entity>path</entity> <entity>weights</entity> from <entity>training</entity>. <entity>Experimental</entity> <entity>results</entity> show that our <entity>method</entity> significantly outperforms state-of-the-art <entity>syntactic</entity> <entity>relation-based methods</entity> by up to 20% in MRR.
</abstract></paper>

<paper id="C90-3063" for="C90-3060"><title><entity>Automatic</entity> <entity>Processing</entity> Of Large <entity>Corpora</entity> For The <entity>Resolution</entity> Of Anaphora References
</title><abstract>
"<entity>Manual</entity> <entity>acquisition</entity> of <entity>semantic</entity> <entity>constraints</entity> in broad <entity>domains</entity> is very expensive. This <entity>paper</entity> presents an <entity>automatic</entity> <entity>scheme</entity> for collecting <entity>statistics</entity> on cooccurrence <entity>patterns</entity> in a large <entity>corpus</entity>. To a large <entity>extent</entity>, these <entity>statistics</entity> reflect <entity>semantic</entity> <entity>constraints</entity> and thus are used to <entity>disambiguate</entity> anaphora <entity>references</entity> and <entity>syntactic</entity> <entity>ambiguities</entity>. The <entity>scheme</entity> was <entity>implemented</entity> by gathering <entity>statistics</entity> on the <entity>output</entity> of other linguistic toots. An <entity>experiment</entity> was <entity>performed</entity> to resolve <entity>references</entity> of the pronoun ""it"" in <entity>sentences</entity> that were randomly selected from the <entity>corpus</entity>. The <entity>results</entity> of the <entity>experiment</entity> show that in most of the <entity>cases</entity> the cooccurrence <entity>statistics</entity> indeed reflect the <entity>semantic</entity> <entity>constraints</entity> and thus <entity>provide</entity> a <entity>basis</entity> for a useful <entity>disambiguation</entity> <entity>tool</entity>. "
</abstract></paper>

<paper id="C04-1011"><title>
Kullback-Leibler <entity>Distance</entity> Between Probabilistic <entity>Context-</entity>Free Grammars And Probabilistic Finite <entity>Automata</entity></title><abstract>
We consider the <entity>problem</entity> of <entity>computing</entity> the Kullback-Leibler <entity>distance</entity>, also <entity>called</entity> the <entity>relative</entity> <entity>entropy</entity>, between a probabilistic <entity>context-free</entity> grammar and a probabilistic finite automaton. We show that there is a <entity>closed-form</entity> (analytical) <entity>solution</entity> for one <entity>part</entity> of the Kullback-Leibler <entity>distance</entity>, viz. the <entity>cross-entropy</entity>. We discuss several <entity>applications</entity> of the <entity>result</entity> to the <entity>problem</entity> of distributional <entity>approximation</entity> of probabilistic <entity>context-free</entity> grammars by means of probabilistic finite automata.
</abstract></paper>

<paper id="E06-3005"><title><entity>Developing</entity> An <entity>Approach</entity> For Why-<entity>Question Answering</entity></title><abstract>
In the <entity>current</entity> <entity>project</entity>, we aim at <entity>developing</entity> an <entity>approach</entity> for automatically answering why-questions. We created a<entity>data</entity> <entity>collection</entity> for <entity>research</entity>, <entity>development</entity> and <entity>evaluation</entity> of a <entity>method</entity> for automatically answering why-questions (why-QA) whywhywhy
</abstract></paper>

<paper id="A94-1037"><title>
Spelling <entity>Correction</entity> In Agglutinative <entity>Languages</entity></title><abstract><entity>Methods</entity> <entity>developed</entity> for <entity>spelling</entity> <entity>correction</entity> for <entity>languages</entity> like <entity>English</entity> (see the <entity>review</entity> by <PERSON>Kukich</PERSON> (Ku-kich, 1992)) are not readily applicable to agglutinative <entity>languages</entity>. This poster presents an <entity>approach</entity> to <entity>spelling</entity> <entity>correction</entity> in agglutinative <entity>languages</entity> that is <entity>based</entity> on <entity>two-level</entity> <entity>morphology</entity> and a <entity>dynamic-programming</entity> <entity>based</entity> <entity>search algorithm</entity>. After an <entity>overview</entity> of our <entity>approach</entity>, we present <entity>results</entity> from <entity>experiments</entity> with <entity>spelling</entity> <entity>correction</entity> in Turkish.
</abstract></paper>

<paper id="H94-1102"><title><entity>Robust</entity> <entity>Continuous Speech Recognition</entity> <entity>Technology</entity> <entity>Program</entity> <entity>Summary</entity></title><abstract>
The major <entity>objective</entity> of this <entity>program</entity> is to <entity>develop</entity> and demonstrate <entity>robust</entity>, high <entity>performance</entity> <entity>continuous speech recognition</entity> (CSR) <entity>techniques</entity> focussed on <entity>application</entity> in <entity>Spoken Language</entity> <entity>Systems</entity> (SLS) which will enhance the <entity>effectiveness</entity> of military and civilian <entity>computer-based systems</entity>. A key complementary <entity>objective</entity> is to define and <entity>develop</entity> <entity>applications</entity> of <entity>robust</entity> <entity>speech recognition</entity> and <entity>understanding systems</entity>, and to <entity>help</entity> catalyze the <entity>transition</entity> of spoken <entity>language technology</entity> into military and civilian <entity>systems</entity>, with particular <entity>focus</entity> on <entity>application</entity> of <entity>robust</entity> CSR to mobile military command and <entity>control</entity>. The <entity>research</entity> <entity>effort</entity> focusses on <entity>developing</entity> <entity>advanced</entity> acoustic modelling, rapid <entity>search</entity>, and <entity>recognition-time</entity> <entity>adaptation</entity> <entity>techniques</entity> for <entity>robust</entity> <entity>large-vocabulary</entity> CSR, and on <entity>applying</entity> these <entity>techniques</entity> to the new ARPA <entity>large-vocabulary</entity> CSR <entity>corpora</entity> and to military <entity>application</entity> <entity>tasks</entity>.
</abstract></paper>

<paper id="P98-1118"><title>
A <entity>Framework</entity> for Customizable <entity>Generation</entity> of <entity>Hypertext</entity> Presentations
</title><abstract>
In this <entity>paper</entity>, we present a <entity>framework</entity>, Presentor, for the <entity>development</entity> and customization of <entity>hypertext</entity> <entity>presentation</entity> <entity>generators</entity>. Presentor offers intuitive and powerful declarative <entity>languages</entity> specifying the <entity>presentation</entity> at different <entity>levels</entity>: macro-planning, micro-planning, <entity>realization</entity>, and <entity>formatting</entity>. Presentor is <entity>implemented</entity> and is portable <entity>cross-platform</entity> and <entity>cross-domain</entity>. It has been used with <entity>success</entity> in several <entity>application</entity> <entity>domains</entity> <entity>including</entity> weather forecasting, <entity>object</entity> <entity>modeling</entity>, <entity>system</entity> <entity>description</entity> and <entity>requirements</entity> <entity>summarization</entity>.
</abstract></paper>

<paper id="A92-1023"><title>
A Practical <entity>Methodology</entity> For The <entity>Evaluation</entity> Of <entity>Spoken Language</entity> <entity>Systems</entity></title><abstract>
"A meaningful <entity>evaluation</entity> <entity>methodology</entity> can <entity>advance</entity> the state-of-the-art by encouraging mature, <entity>practical applications</entity> rather than ""toy"" <entity>implementations</entity>. <entity>Evaluation</entity> is also crucial to assessing competing <entity>claims</entity> and identifying promising technical <entity>approaches</entity>. While work in <entity>speech recognition</entity> (SR) has a history of <entity>evaluation</entity> <entity>methodologies</entity> that permit <entity>comparison</entity> among various <entity>systems</entity>, until recently no <entity>methodology</entity> existed for either <entity>developers</entity> of <entity>natural language</entity> (NL) <entity>interfaces</entity> or <entity>researchers</entity> in <entity>speech</entity> <entity>understanding</entity> (SU) to <entity>evaluate</entity> and compare the <entity>systems</entity> they <entity>developed</entity>.Recently considerable <entity>progress</entity> has been made by a <entity>number</entity> of groups involved in the DARPA <entity>Spoken Language</entity> <entity>Systems</entity> (SLS) <entity>program</entity> to agree on a <entity>methodology</entity> for comparative <entity>evaluation</entity> of SLS <entity>systems</entity>, and that <entity>methodology</entity> has been put into <entity>practice</entity> several <entity>times</entity> in comparative <entity>tests</entity> of several SLS <entity>systems</entity>. These <entity>evaluations</entity> are probably the only NL <entity>evaluations</entity> other than the <entity>series</entity> of <entity>Message</entity> <entity>Understanding</entity> Conferences ( <BIBLIO>Sundheim, 1989</BIBLIO> ; <BIBLIO>Sundheim, 1991</BIBLIO> ) to have been <entity>developed</entity> and used by a group of <entity>researchers</entity> at different <entity>sites</entity>, although several excellent <entity>workshops</entity> have been held to <entity>study</entity> some of these <entity>problems</entity> ( <PERSON><entity>Palmer</entity></PERSON> This <entity>paper</entity> describes a practical ""black-box"" <entity>methodology</entity> for <entity>automatic evaluation</entity> of <entity>question-answering</entity> NL <entity>systems</entity>. While each new <entity>application</entity> <entity>domain</entity> will <entity>require</entity> some <entity>development</entity> of special <entity>resources</entity>, the heart of the <entity>methodology</entity> is <entity>domain-independent</entity>, and it can be used with either <entity>speech</entity> or <entity>text</entity> <entity>input</entity>. The particular <entity>characteristics</entity> of the <entity>approach</entity> are described in the <entity>following</entity> <entity>section</entity>: subsequent <entity>sections</entity> present its <entity>implementation</entity> in the DARPA SLS <entity>community</entity>, and some <entity>problems</entity> and <entity>directions</entity> for future <entity>development</entity>."
</abstract></paper>

<paper id="P06-1053"><title>
Integrating <entity>Syntactic</entity> Priming Into An Incremental Probabilistic <entity>Parser</entity>, With An <entity>Application</entity> To Psycholinguistic <entity>Modeling</entity></title><abstract>
The psycholinguistic <entity>literature</entity> <entity>provides</entity> <entity>evidence</entity> for <entity>syntactic</entity> priming, i.e., the tendency to repeat <entity>structures</entity>. This <entity>paper</entity> describes a <entity>method</entity> for incorporating priming into an incremental probabilistic <entity>parser</entity>. Three <entity>models</entity> are compared, which involve priming of <entity>rules</entity> between <entity>sentences</entity>, within <entity>sentences</entity>, and within coordinate <entity>structures</entity>. These <entity>models</entity> simulate the reading <entity>time</entity> <entity>advantage</entity> for parallel <entity>structures</entity> found in human data, and also <entity>yield</entity> a small <entity>increase</entity> in overall <entity>parsing</entity> <entity>accuracy</entity>.
</abstract></paper>

</corpus>