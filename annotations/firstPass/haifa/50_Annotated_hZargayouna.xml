<?xml version="1.0" encoding="UTF-8"?>
<corpus>
    <paper id="P02-1059"><title>
        <entity>Supervised Ranking</entity> In <entity>Open-Domain Text Summarization</entity></title><abstract>
            The paper proposes and empirically motivates an integration of <entity>supervised learning</entity> with <entity>unsupervised learning</entity> to deal with human biases in <entity>summarization</entity>. In particular, we explore the use of <entity>probabilistic decision tree</entity> within the <entity>clustering framework</entity> to account for the variation as well as regularity in <entity>human created summaries</entity>. The <entity>corpus</entity> of human created extracts is created from a <entity>newspaper corpus</entity> and used as a test set. We build <entity>probabilistic decision trees</entity> of different flavors and integrate each of them with the <entity>clustering framework</entity>. Experiments with the <entity>corpus</entity> demonstrate that the mixture of the two paradigms generally gives a significant boost in performance compared to cases where either ofthe two is considered alone.
        </abstract></paper>
    <paper id="P02-1002"><title>
        <entity>Sequential Conditional Generalized Iterative Scaling</entity></title><abstract>
            We describe a speedup for training <entity>conditional maximum entropy models</entity>. The algorithm is a simple variation on <entity>Generalized Iterative Scaling</entity>, but converges roughly an order of magnitude faster, depending on the number of  constraints, and the way speed is measured. Rather than attempting to train  all model parameters simultaneously, the  algorithm trains them sequentially. The algorithm is easy to implement, typically uses only slightly more memory, and will lead to improvementsfor most <entity>maximum entropy</entity> problems.
        </abstract></paper>
    <paper id="C00-2123"><title><entity>Word Re-Ordering</entity> And <entity>DP-Based Search</entity> In <entity>Statistical Machine Translation</entity></title><abstract>
        In this paper, we describe a search procedure for <entity>statistical machine translation (MT) </entity> based on <entity>dynamic programming (DP)</entity>. Starting from a DP-based solution to the traveling salesman problem, we present a novel technique to restrict the possible <entity>word reordering</entity>  between source and target language in order to achieve an efficient search algorithm. A search restriction especially useful for the translation direction from <entity>German </entity>to <entity>English</entity> is presented. The experimental tests are carried out on the <entity>Verbmobil task</entity> (<entity>German-English</entity>, 8000-word vocabulary), which is a limited-domain <entity>spoken-language task</entity>.
    </abstract></paper>
    
    <paper id="C96-1055"><title>Role Of <entity>Word Sense Disambiguation</entity> In <entity>Lexical Acquisition</entity>: Predicting <entity>Semantics</entity> From <entity>Syntactic Cues</entity>
    </title><abstract>
        This paper addresses the issue of <entity>word-sense ambiguity</entity> in <entity>extraction</entity> from <entity>machine-readable resources</entity> for the construction of <entity>large-scale knowledge sources</entity>. We describe two experiments: one which ignored <entity>word-sense</entity> distinctions, resulting in 6.3% <entity>accuracy</entity> for <entity>semantic classification</entity> of <entity>verbs</entity> based on ( <BIBLIO>Levin, 1993</BIBLIO> ); and one which exploited <entity>word-sense</entity> distinctions, resulting in 97.9% <entity>accuracy</entity>. These experiments were dual purpose: (1) to validate the central thesis of the work of ( <BIBLIO>Levin, 1993</BIBLIO> ), i.e., that <entity>verb semantics</entity> and <entity>syntactic behavior</entity> are predictably related; (2) to demonstrate that a 15-fold improvement can be achieved in deriving <entity>semantic information</entity> from <entity>syntactic cues</entity> if we first divide the <entity>syntactic cues</entity> into distinct groupings that correlate with different <entity>word senses</entity>. Finally, we show that we can provide effective <entity>acquisition techniques</entity> for novel <entity>word senses</entity>  using a combination of online sources.
    </abstract></paper>
    
    <paper id="M91-1029"><title>
        PRC Inc: Description Of The <entity>PAKTUS System</entity> Used For <entity>MUC-3</entity>
    </title><abstract>
        The PRC Adaptive <entity>Knowledge-based Text Understanding System (PAKTUS)</entity> has been under development as an Independent Research and Development project at PRC since 1984. The objective is a generic system of tools, including a <entity>core English lexicon</entity>, <entity>grammar, and concept representations</entity>, for building <entity>natural language processing (NLP) systems</entity> for <entity>text understanding</entity>. Systems built with <entity>PAKTUS</entity> are intended to generate input to <entity>knowledge based systems</entity> or<entity>data base systems</entity>. Input to the <entity>NLP system</entity> is typically derived from an existing <entity>electronic message stream</entity>, such as a <entity>news wire</entity>. <entity>PAKTUS</entity> supports the adaptation of the generic core to a variety of domains: <entity>JINTACCS messages</entity>, <entity>RAINFORM messages</entity>, <entity>news reports</entity> about a specific type of event, such as financial transfers or terrorist acts, etc., by acquiring  <entity>sublanguage and domain-specific grammar</entity>, <entity>words, conceptual mappings</entity>, and <entity>discourse patterns</entity>. The long-term goal is a system that can support the processing of relatively long discourses in domains that are fairly broad with a high rate of success.
    </abstract></paper>
    
    <paper id="H93-1113"><title><entity>Natural Language</entity> Research</title><abstract>
        The main objective is basic research and system development leading to (1) characterization of information carried by (a) <entity>syntax, semantics, and discourse structure</entity>, (b) their relation to information carried by intonation, and (c) development of methods for using this information for <entity>generation</entity> and <entity>understanding</entity>; (2) development of architectures for integration of <entity>utterance</entity> planning with lexical, syntactic and intonational choice; (3) development of incremental strategies for using <entity>syntactic, semantic, and pragmatic knowledge</entity> in <entity>understanding and generating language</entity>.
    </abstract></paper>
    
    <paper id="P98-1088"><title>
        Memoisation for <entity>Glue Language Deduction</entity> and <entity>Categorial Parsing</entity></title><abstract>
            "The multiplicative fragment of <entity>linear logic</entity> has found a number of applications in <entity>computational linguistics</entity>: in the ""<entity>glue language"" approach</entity> to <entity>LFG semantics</entity>, and in the formulation and <entity>parsing</entity> of various <entity>categorial grammars</entity>. These applications call for efficient <entity>deduction methods</entity>. Although a number of <entity>deduction methods</entity> for <entity>multiplicative linear logic</entity> are known, none of them are <entity>tabular methods</entity>, which bring a substantial efficiency gain by avoiding redundant computation (cf. <entity>chart methods</entity> in <entity>CFG parsing</entity>): this paper presents such a method, and discusses its use in relation to the above applications."
        </abstract></paper>
    
    <paper id="E06-1045"><title><entity>Data-Driven Generation</entity> Of Emphatic Facial Displays
    </title><abstract>
        We describe an implementation of <entity>data-driven selection</entity> of emphatic facial displays for an <entity>embodied conversational agent</entity> in a <entity>dialogue system</entity>. A corpus of sentencesin the domain of the target <entity>dialogue system</entity> was recorded, and the <entity>facial displays</entity> used by the <entity>speaker</entity> were annotated. The data from those <entity>recordings</entity> was used in a range of <entity>models for generating facial displays</entity>, each <entity>model</entity> making use of a different amount of <entity>context</entity> or choosing <entity>displays</entity> differently within a <entity>context</entity>. The <entity>models</entity> were evaluated in two ways: by <entity>cross-validation</entity> against the <entity>corpus</entity>, and by asking users to rate the output. The <entity>predictions</entity> of the <entity>cross-validation study</entity> differed from the actual user ratings. While the <entity>cross-validation</entity> gave the highest scores to <entity>models</entity> making a majority choice within a <entity>context</entity>, the user study showed a significant preference for <entity>models</entity> that produced more variation. This preference was especially strong among the female subjects.
    </abstract></paper>
    
</corpus>
